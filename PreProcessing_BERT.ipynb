{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZPw1NkfGLCd",
        "outputId": "636b9b59-7c03-4a5e-fd17-3e5bb4c8e517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XgPMInDHmRY",
        "outputId": "92571650-a0e7-41e2-da37-cc802f1ab1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx==2.4 in /usr/local/lib/python3.10/dist-packages (2.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx==2.4) (4.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl\n",
        "!pip install torch_geometric\n",
        "!pip install networkx==2.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJY1LLeMGLCf",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import networkx as nx\n",
        "import nltk\n",
        "\n",
        "import tqdm\n",
        "# import en_core_web_lg\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "import spacy\n",
        "from time import time\n",
        "import dgl\n",
        "from scipy import sparse\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqEK4EpxGLCg",
        "outputId": "21a488c5-9825-4056-eadb-53395e1aa508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq0N-fSP78lI",
        "outputId": "24953ea5-7057-4db3-9fd6-67e6221209f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUjMVDgvzVFP"
      },
      "source": [
        "# Load tweet file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD03dJLS7zCx"
      },
      "outputs": [],
      "source": [
        "p_part1 = '68841_tweets_multiclasses_filtered_0722_part1.npy'\n",
        "p_part2 = '68841_tweets_multiclasses_filtered_0722_part2.npy'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb7rtMvEGLCi"
      },
      "source": [
        "# Concatenating The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpm2PHOx8wp2",
        "outputId": "2608b2c8-6aef-4b8a-d2b1-6dfe03920167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Data Loaded...\n",
            "[INFO] Data converted to dataframe...\n"
          ]
        }
      ],
      "source": [
        "df_np_part1 = np.load(p_part1, allow_pickle=True)\n",
        "df_np_part2 = np.load(p_part2, allow_pickle=True)\n",
        "df_np = np.concatenate((df_np_part1, df_np_part2), axis = 0)\n",
        "print(\"[INFO] Data Loaded...\")\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data=df_np, columns=[\"event_id\", \"tweet_id\", \"text\", \"user_id\", \"created_at\", \"user_loc\",\\\n",
        "    \"place_type\", \"place_full_name\", \"place_country_code\", \"hashtags\", \"user_mentions\", \"image_urls\", \"entities\", \n",
        "    \"words\", \"filtered_words\", \"sampled_words\"])\n",
        "\n",
        "print(\"[INFO] Data converted to dataframe...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U5eFwSj80mm",
        "outputId": "8984e462-5daf-4c8b-82de-7a473ce8d303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(68841, 16)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBfIez3AGLCj",
        "outputId": "4681cfcb-90f4-4f78-9941-98d6eb422845"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-23cfcd12-ee1a-4326-b8a2-14453515e470\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_loc</th>\n",
              "      <th>place_type</th>\n",
              "      <th>place_full_name</th>\n",
              "      <th>place_country_code</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_mentions</th>\n",
              "      <th>image_urls</th>\n",
              "      <th>entities</th>\n",
              "      <th>words</th>\n",
              "      <th>filtered_words</th>\n",
              "      <th>sampled_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>256292946331181056</td>\n",
              "      <td>Nobel prize in literature to be announced http...</td>\n",
              "      <td>47667947</td>\n",
              "      <td>2012-10-11 07:19:34</td>\n",
              "      <td>Munich, Germany</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[literature, Nobel, prize, announce]</td>\n",
              "      <td>[literature, nobel, prize, announce]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>256333064467279872</td>\n",
              "      <td>“@marvicleonen: Is it true that UP won UAAP ba...</td>\n",
              "      <td>67518107</td>\n",
              "      <td>2012-10-11 09:58:59</td>\n",
              "      <td>Philippines</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[28775032]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(UP, ORG), (Next year, DATE), (Dean, PERSON)]</td>\n",
              "      <td>[Dean, Sure, year, yan, na, \", basketball, tru...</td>\n",
              "      <td>[dean, sure, year, yan, na, basketball, true, ...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>256334302034399232</td>\n",
              "      <td>Congrats, Ateneo! Last na yan ha. Season 76 wi...</td>\n",
              "      <td>97449266</td>\n",
              "      <td>2012-10-11 10:03:54</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(Ateneo, PERSON), (Season 76, PERSON)]</td>\n",
              "      <td>[yan, ☺, na, ha, different, last, Ateneo, cong...</td>\n",
              "      <td>[yan, na, ha, different, last, ateneo, congrat...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>256335853738160128</td>\n",
              "      <td>\"@SMARTPromos: SMART never wants you to be lef...</td>\n",
              "      <td>405138197</td>\n",
              "      <td>2012-10-11 10:10:04</td>\n",
              "      <td>Lost in Dreamland</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[106915372]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(BIG, ORG), (BIG, ORG)]</td>\n",
              "      <td>[never, s, yan, next, na, thing, Ano, leave, t...</td>\n",
              "      <td>[never, yan, next, na, thing, ano, leave, that...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>256346272506712064</td>\n",
              "      <td>CCTV invite hints at Nobel literature prize fo...</td>\n",
              "      <td>197326414</td>\n",
              "      <td>2012-10-11 10:51:28</td>\n",
              "      <td>Taiwan(R.O.C)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...</td>\n",
              "      <td>[invite, prize, Yan, literature, hint, CCTV, N...</td>\n",
              "      <td>[invite, prize, yan, literature, hint, cctv, n...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>256346650132508673</td>\n",
              "      <td>mjzone58: SIR HINDI BYAHE YAN. WALA TALAGANG P...</td>\n",
              "      <td>397051720</td>\n",
              "      <td>2012-10-11 10:52:58</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(WALA, ORG)]</td>\n",
              "      <td>[HINDI, wala, yan, mjzone58, panalo, SIR, BYAH...</td>\n",
              "      <td>[hindi, wala, yan, panalo, sir, byahe, talagan...</td>\n",
              "      <td>[panalo, byahe]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>256349023773024256</td>\n",
              "      <td>BREAKING: The 2012 Nobel Prize for Literature ...</td>\n",
              "      <td>7424642</td>\n",
              "      <td>2012-10-11 11:02:24</td>\n",
              "      <td>Tokyo</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(Nobel Prize for Literature, WORK_OF_ART), (C...</td>\n",
              "      <td>[award, author, Yan, BREAKING, chinese, Litera...</td>\n",
              "      <td>[award, author, yan, breaking, chinese, litera...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>256349178991624192</td>\n",
              "      <td>\"@GuardianBooks: And the #Nobel prize for lite...</td>\n",
              "      <td>24515914</td>\n",
              "      <td>2012-10-11 11:03:01</td>\n",
              "      <td>Montevideo</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[Nobel]</td>\n",
              "      <td>[22001973]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(China, GPE)]</td>\n",
              "      <td>[prize, Chinas, literature, Yan, go, Mo]</td>\n",
              "      <td>[prize, chinas, literature, yan, go, mo]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>256349191863943168</td>\n",
              "      <td>Chinese author Mo Yan wins Nobel prize for lit...</td>\n",
              "      <td>14860646</td>\n",
              "      <td>2012-10-11 11:03:04</td>\n",
              "      <td>Nepal</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(Chinese, NORP), (Mo Yan, PERSON), (Nobel, WO...</td>\n",
              "      <td>[author, prize, win, literature, Nobel, chines...</td>\n",
              "      <td>[author, prize, win, literature, nobel, chines...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>256349325876137984</td>\n",
              "      <td>Congratulations! Mo Yan of this year Nobel Prize!</td>\n",
              "      <td>489617283</td>\n",
              "      <td>2012-10-11 11:03:36</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(Mo Yan, PERSON), (this year, DATE), (Nobel P...</td>\n",
              "      <td>[year, Yan, Congratulations, Prize, Nobel, Mo]</td>\n",
              "      <td>[year, yan, congratulations, prize, nobel, mo]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23cfcd12-ee1a-4326-b8a2-14453515e470')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23cfcd12-ee1a-4326-b8a2-14453515e470 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23cfcd12-ee1a-4326-b8a2-14453515e470');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  event_id            tweet_id  \\\n",
              "0        0  256292946331181056   \n",
              "1        0  256333064467279872   \n",
              "2        0  256334302034399232   \n",
              "3        0  256335853738160128   \n",
              "4        0  256346272506712064   \n",
              "5        0  256346650132508673   \n",
              "6        0  256349023773024256   \n",
              "7        0  256349178991624192   \n",
              "8        0  256349191863943168   \n",
              "9        0  256349325876137984   \n",
              "\n",
              "                                                text    user_id  \\\n",
              "0  Nobel prize in literature to be announced http...   47667947   \n",
              "1  “@marvicleonen: Is it true that UP won UAAP ba...   67518107   \n",
              "2  Congrats, Ateneo! Last na yan ha. Season 76 wi...   97449266   \n",
              "3  \"@SMARTPromos: SMART never wants you to be lef...  405138197   \n",
              "4  CCTV invite hints at Nobel literature prize fo...  197326414   \n",
              "5  mjzone58: SIR HINDI BYAHE YAN. WALA TALAGANG P...  397051720   \n",
              "6  BREAKING: The 2012 Nobel Prize for Literature ...    7424642   \n",
              "7  \"@GuardianBooks: And the #Nobel prize for lite...   24515914   \n",
              "8  Chinese author Mo Yan wins Nobel prize for lit...   14860646   \n",
              "9  Congratulations! Mo Yan of this year Nobel Prize!  489617283   \n",
              "\n",
              "           created_at           user_loc place_type place_full_name  \\\n",
              "0 2012-10-11 07:19:34    Munich, Germany                              \n",
              "1 2012-10-11 09:58:59        Philippines                              \n",
              "2 2012-10-11 10:03:54                                                 \n",
              "3 2012-10-11 10:10:04  Lost in Dreamland                              \n",
              "4 2012-10-11 10:51:28      Taiwan(R.O.C)                              \n",
              "5 2012-10-11 10:52:58                                                 \n",
              "6 2012-10-11 11:02:24              Tokyo                              \n",
              "7 2012-10-11 11:03:01         Montevideo                              \n",
              "8 2012-10-11 11:03:04              Nepal                              \n",
              "9 2012-10-11 11:03:36                                                 \n",
              "\n",
              "  place_country_code hashtags user_mentions image_urls  \\\n",
              "0                          []            []         []   \n",
              "1                          []    [28775032]         []   \n",
              "2                          []            []         []   \n",
              "3                          []   [106915372]         []   \n",
              "4                          []            []         []   \n",
              "5                          []            []         []   \n",
              "6                          []            []         []   \n",
              "7                     [Nobel]    [22001973]         []   \n",
              "8                          []            []         []   \n",
              "9                          []            []         []   \n",
              "\n",
              "                                            entities  \\\n",
              "0                                                 []   \n",
              "1     [(UP, ORG), (Next year, DATE), (Dean, PERSON)]   \n",
              "2            [(Ateneo, PERSON), (Season 76, PERSON)]   \n",
              "3                           [(BIG, ORG), (BIG, ORG)]   \n",
              "4  [(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...   \n",
              "5                                      [(WALA, ORG)]   \n",
              "6  [(Nobel Prize for Literature, WORK_OF_ART), (C...   \n",
              "7                                     [(China, GPE)]   \n",
              "8  [(Chinese, NORP), (Mo Yan, PERSON), (Nobel, WO...   \n",
              "9  [(Mo Yan, PERSON), (this year, DATE), (Nobel P...   \n",
              "\n",
              "                                               words  \\\n",
              "0               [literature, Nobel, prize, announce]   \n",
              "1  [Dean, Sure, year, yan, na, \", basketball, tru...   \n",
              "2  [yan, ☺, na, ha, different, last, Ateneo, cong...   \n",
              "3  [never, s, yan, next, na, thing, Ano, leave, t...   \n",
              "4  [invite, prize, Yan, literature, hint, CCTV, N...   \n",
              "5  [HINDI, wala, yan, mjzone58, panalo, SIR, BYAH...   \n",
              "6  [award, author, Yan, BREAKING, chinese, Litera...   \n",
              "7           [prize, Chinas, literature, Yan, go, Mo]   \n",
              "8  [author, prize, win, literature, Nobel, chines...   \n",
              "9     [year, Yan, Congratulations, Prize, Nobel, Mo]   \n",
              "\n",
              "                                      filtered_words    sampled_words  \n",
              "0               [literature, nobel, prize, announce]               []  \n",
              "1  [dean, sure, year, yan, na, basketball, true, ...               []  \n",
              "2  [yan, na, ha, different, last, ateneo, congrat...               []  \n",
              "3  [never, yan, next, na, thing, ano, leave, that...               []  \n",
              "4  [invite, prize, yan, literature, hint, cctv, n...               []  \n",
              "5  [hindi, wala, yan, panalo, sir, byahe, talagan...  [panalo, byahe]  \n",
              "6  [award, author, yan, breaking, chinese, litera...               []  \n",
              "7           [prize, chinas, literature, yan, go, mo]               []  \n",
              "8  [author, prize, win, literature, nobel, chines...               []  \n",
              "9     [year, yan, congratulations, prize, nobel, mo]               []  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgah06TXKnLs"
      },
      "outputs": [],
      "source": [
        "df.text = df.text.str.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orYIk4hFLf4n",
        "outputId": "778bf8c3-ba10-4b7f-8778-512b70d83728"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        Nobel prize in literature to be announced http...\n",
              "1        “@marvicleonen: Is it true that UP won UAAP ba...\n",
              "2        Congrats, Ateneo! Last na yan ha. Season 76 wi...\n",
              "3        \"@SMARTPromos: SMART never wants you to be lef...\n",
              "4        CCTV invite hints at Nobel literature prize fo...\n",
              "                               ...                        \n",
              "68836    Oh my god it's like the World Series all over ...\n",
              "68837    Looks like the yankees are winning the world s...\n",
              "68838    The Yankees are going to win the world Series ...\n",
              "68839    Cubs last World Series win, they were keeping ...\n",
              "68840    I hate to say this but the giants are going to...\n",
              "Name: text, Length: 68841, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS-YKLhHJiZ8",
        "outputId": "a2586718-c011-4e74-a814-621c78bdc9f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "event_id                      object\n",
              "tweet_id                      object\n",
              "text                          object\n",
              "user_id                       object\n",
              "created_at            datetime64[ns]\n",
              "user_loc                      object\n",
              "place_type                    object\n",
              "place_full_name               object\n",
              "place_country_code            object\n",
              "hashtags                      object\n",
              "user_mentions                 object\n",
              "image_urls                    object\n",
              "entities                      object\n",
              "words                         object\n",
              "filtered_words                object\n",
              "sampled_words                 object\n",
              "dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuFCgSd-KLKp",
        "outputId": "fc994653-aa58-4545-e301-fee16170ddb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "event_id              0\n",
              "tweet_id              0\n",
              "text                  0\n",
              "user_id               0\n",
              "created_at            0\n",
              "user_loc              0\n",
              "place_type            0\n",
              "place_full_name       0\n",
              "place_country_code    0\n",
              "hashtags              0\n",
              "user_mentions         0\n",
              "image_urls            0\n",
              "entities              0\n",
              "words                 0\n",
              "filtered_words        0\n",
              "sampled_words         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vih0WHTPGLCk"
      },
      "source": [
        "# Defining preprocessing functions for TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Epbg4vUrBSz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = str(text).lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove digits\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    return text\n",
        "\n",
        "def tokenize_text(text):\n",
        "    # Tokenize text using TweetTokenizer\n",
        "    tokenizer = TweetTokenizer()\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    # Lemmatize tokens using WordNetLemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return lemmas\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    # Remove stop words using NLTK's English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    return filtered_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxfonNxgrKeH"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to the text column\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "df['text'] = df['text'].apply(tokenize_text)\n",
        "df['text'] = df['text'].apply(lemmatize_tokens)\n",
        "df['text'] = df['text'].apply(remove_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDuAxHprGLCl",
        "outputId": "4041f5a0-e6f8-4d99-ebb8-fba8e2b6ee54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-07836841-d06b-44b3-aa20-cbb74373a5ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_loc</th>\n",
              "      <th>place_type</th>\n",
              "      <th>place_full_name</th>\n",
              "      <th>place_country_code</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_mentions</th>\n",
              "      <th>image_urls</th>\n",
              "      <th>entities</th>\n",
              "      <th>words</th>\n",
              "      <th>filtered_words</th>\n",
              "      <th>sampled_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>256292946331181056</td>\n",
              "      <td>[nobel, prize, literature, announced]</td>\n",
              "      <td>47667947</td>\n",
              "      <td>2012-10-11 07:19:34</td>\n",
              "      <td>Munich, Germany</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[literature, Nobel, prize, announce]</td>\n",
              "      <td>[literature, nobel, prize, announce]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>256333064467279872</td>\n",
              "      <td>[“, marvicleonen, true, uaap, basketball, ”, n...</td>\n",
              "      <td>67518107</td>\n",
              "      <td>2012-10-11 09:58:59</td>\n",
              "      <td>Philippines</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[28775032]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(UP, ORG), (Next year, DATE), (Dean, PERSON)]</td>\n",
              "      <td>[Dean, Sure, year, yan, na, \", basketball, tru...</td>\n",
              "      <td>[dean, sure, year, yan, na, basketball, true, ...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>256334302034399232</td>\n",
              "      <td>[congrats, ateneo, last, na, yan, ha, season, ...</td>\n",
              "      <td>97449266</td>\n",
              "      <td>2012-10-11 10:03:54</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(Ateneo, PERSON), (Season 76, PERSON)]</td>\n",
              "      <td>[yan, ☺, na, ha, different, last, Ateneo, cong...</td>\n",
              "      <td>[yan, na, ha, different, last, ateneo, congrat...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>256335853738160128</td>\n",
              "      <td>[smartpromos, smart, never, want, left, behind...</td>\n",
              "      <td>405138197</td>\n",
              "      <td>2012-10-11 10:10:04</td>\n",
              "      <td>Lost in Dreamland</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[106915372]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(BIG, ORG), (BIG, ORG)]</td>\n",
              "      <td>[never, s, yan, next, na, thing, Ano, leave, t...</td>\n",
              "      <td>[never, yan, next, na, thing, ano, leave, that...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>256346272506712064</td>\n",
              "      <td>[cctv, invite, hint, nobel, literature, prize,...</td>\n",
              "      <td>197326414</td>\n",
              "      <td>2012-10-11 10:51:28</td>\n",
              "      <td>Taiwan(R.O.C)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...</td>\n",
              "      <td>[invite, prize, Yan, literature, hint, CCTV, N...</td>\n",
              "      <td>[invite, prize, yan, literature, hint, cctv, n...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07836841-d06b-44b3-aa20-cbb74373a5ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07836841-d06b-44b3-aa20-cbb74373a5ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07836841-d06b-44b3-aa20-cbb74373a5ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  event_id            tweet_id  \\\n",
              "0        0  256292946331181056   \n",
              "1        0  256333064467279872   \n",
              "2        0  256334302034399232   \n",
              "3        0  256335853738160128   \n",
              "4        0  256346272506712064   \n",
              "\n",
              "                                                text    user_id  \\\n",
              "0              [nobel, prize, literature, announced]   47667947   \n",
              "1  [“, marvicleonen, true, uaap, basketball, ”, n...   67518107   \n",
              "2  [congrats, ateneo, last, na, yan, ha, season, ...   97449266   \n",
              "3  [smartpromos, smart, never, want, left, behind...  405138197   \n",
              "4  [cctv, invite, hint, nobel, literature, prize,...  197326414   \n",
              "\n",
              "           created_at           user_loc place_type place_full_name  \\\n",
              "0 2012-10-11 07:19:34    Munich, Germany                              \n",
              "1 2012-10-11 09:58:59        Philippines                              \n",
              "2 2012-10-11 10:03:54                                                 \n",
              "3 2012-10-11 10:10:04  Lost in Dreamland                              \n",
              "4 2012-10-11 10:51:28      Taiwan(R.O.C)                              \n",
              "\n",
              "  place_country_code hashtags user_mentions image_urls  \\\n",
              "0                          []            []         []   \n",
              "1                          []    [28775032]         []   \n",
              "2                          []            []         []   \n",
              "3                          []   [106915372]         []   \n",
              "4                          []            []         []   \n",
              "\n",
              "                                            entities  \\\n",
              "0                                                 []   \n",
              "1     [(UP, ORG), (Next year, DATE), (Dean, PERSON)]   \n",
              "2            [(Ateneo, PERSON), (Season 76, PERSON)]   \n",
              "3                           [(BIG, ORG), (BIG, ORG)]   \n",
              "4  [(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...   \n",
              "\n",
              "                                               words  \\\n",
              "0               [literature, Nobel, prize, announce]   \n",
              "1  [Dean, Sure, year, yan, na, \", basketball, tru...   \n",
              "2  [yan, ☺, na, ha, different, last, Ateneo, cong...   \n",
              "3  [never, s, yan, next, na, thing, Ano, leave, t...   \n",
              "4  [invite, prize, Yan, literature, hint, CCTV, N...   \n",
              "\n",
              "                                      filtered_words sampled_words  \n",
              "0               [literature, nobel, prize, announce]            []  \n",
              "1  [dean, sure, year, yan, na, basketball, true, ...            []  \n",
              "2  [yan, na, ha, different, last, ateneo, congrat...            []  \n",
              "3  [never, yan, next, na, thing, ano, leave, that...            []  \n",
              "4  [invite, prize, yan, literature, hint, cctv, n...            []  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAj25j7-v-hv"
      },
      "source": [
        "# Convert Date and Time in Numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4nP0dQNGLCm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5h2nuiMGLCm"
      },
      "outputs": [],
      "source": [
        "# sort data in DATAFRAME 1 by time\n",
        "df = df.sort_values(by='created_at').reset_index()\n",
        "# append date\n",
        "df['date'] = [d.date() for d in df['created_at']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzq1oBbeGLCm"
      },
      "outputs": [],
      "source": [
        "# df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "#\n",
        "# # convert datetime column to numeric format\n",
        "# df['created_at'] = pd.to_numeric(df['created_at'].dt.strftime('%Y%m%d%H%M%S'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTIkLB6TGLCm",
        "outputId": "0450caae-124c-45e7-8b40-b6d3227cfc9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-57cb36c6-ead5-47be-987b-cd8d3d473286\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>event_id</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_loc</th>\n",
              "      <th>place_type</th>\n",
              "      <th>place_full_name</th>\n",
              "      <th>place_country_code</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_mentions</th>\n",
              "      <th>image_urls</th>\n",
              "      <th>entities</th>\n",
              "      <th>words</th>\n",
              "      <th>filtered_words</th>\n",
              "      <th>sampled_words</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>61124</td>\n",
              "      <td>394</td>\n",
              "      <td>255819992157786112</td>\n",
              "      <td>[hiphop, award, bout, live]</td>\n",
              "      <td>250870763</td>\n",
              "      <td>2012-10-10 00:00:13</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[award, live, bout, hiphop]</td>\n",
              "      <td>[award, live, bout, hiphop]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-10-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61125</td>\n",
              "      <td>394</td>\n",
              "      <td>255820118095978496</td>\n",
              "      <td>[hiphop, award, time]</td>\n",
              "      <td>28026779</td>\n",
              "      <td>2012-10-10 00:00:43</td>\n",
              "      <td>SoundCloud/RaRaSupaStar</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[HIPHOP, AWARDS, time]</td>\n",
              "      <td>[hiphop, awards, time]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-10-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61126</td>\n",
              "      <td>394</td>\n",
              "      <td>255820147489636353</td>\n",
              "      <td>[bet, hiphop, award]</td>\n",
              "      <td>566825483</td>\n",
              "      <td>2012-10-10 00:00:50</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(Bet, GPE)]</td>\n",
              "      <td>[award, bet, hiphop]</td>\n",
              "      <td>[award, bet, hiphop]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-10-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61127</td>\n",
              "      <td>394</td>\n",
              "      <td>255820164023595008</td>\n",
              "      <td>[bet, hiphop, award]</td>\n",
              "      <td>197834311</td>\n",
              "      <td>2012-10-10 00:00:54</td>\n",
              "      <td>Saint Lucia ☀️🌴🇱🇨</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[HipHop, BET, award]</td>\n",
              "      <td>[hiphop, bet, award]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-10-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61128</td>\n",
              "      <td>394</td>\n",
              "      <td>255820180884701184</td>\n",
              "      <td>[watchin, da, bet, hiphop, award]</td>\n",
              "      <td>439490861</td>\n",
              "      <td>2012-10-10 00:00:58</td>\n",
              "      <td>Michigan, USA</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Hiphop, Watchin, Awards, Da, BET]</td>\n",
              "      <td>[hiphop, watchin, awards, da, bet]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-10-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57cb36c6-ead5-47be-987b-cd8d3d473286')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57cb36c6-ead5-47be-987b-cd8d3d473286 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57cb36c6-ead5-47be-987b-cd8d3d473286');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   index event_id            tweet_id                               text  \\\n",
              "0  61124      394  255819992157786112        [hiphop, award, bout, live]   \n",
              "1  61125      394  255820118095978496              [hiphop, award, time]   \n",
              "2  61126      394  255820147489636353               [bet, hiphop, award]   \n",
              "3  61127      394  255820164023595008               [bet, hiphop, award]   \n",
              "4  61128      394  255820180884701184  [watchin, da, bet, hiphop, award]   \n",
              "\n",
              "     user_id          created_at                 user_loc place_type  \\\n",
              "0  250870763 2012-10-10 00:00:13                                       \n",
              "1   28026779 2012-10-10 00:00:43  SoundCloud/RaRaSupaStar              \n",
              "2  566825483 2012-10-10 00:00:50                                       \n",
              "3  197834311 2012-10-10 00:00:54        Saint Lucia ☀️🌴🇱🇨              \n",
              "4  439490861 2012-10-10 00:00:58            Michigan, USA              \n",
              "\n",
              "  place_full_name place_country_code hashtags user_mentions image_urls  \\\n",
              "0                                          []            []         []   \n",
              "1                                          []            []         []   \n",
              "2                                          []            []         []   \n",
              "3                                          []            []         []   \n",
              "4                                          []            []         []   \n",
              "\n",
              "       entities                               words  \\\n",
              "0            []         [award, live, bout, hiphop]   \n",
              "1            []              [HIPHOP, AWARDS, time]   \n",
              "2  [(Bet, GPE)]                [award, bet, hiphop]   \n",
              "3            []                [HipHop, BET, award]   \n",
              "4            []  [Hiphop, Watchin, Awards, Da, BET]   \n",
              "\n",
              "                       filtered_words sampled_words        date  \n",
              "0         [award, live, bout, hiphop]            []  2012-10-10  \n",
              "1              [hiphop, awards, time]            []  2012-10-10  \n",
              "2                [award, bet, hiphop]            []  2012-10-10  \n",
              "3                [hiphop, bet, award]            []  2012-10-10  \n",
              "4  [hiphop, watchin, awards, da, bet]            []  2012-10-10  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJZpJ8VxzLGL"
      },
      "source": [
        "# Load message file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8Zif8Ln74cI"
      },
      "outputs": [],
      "source": [
        "load_path = 'all_df_words_ents_mids.npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTIJ7qDi9DU2",
        "outputId": "dab960fb-a0c4-4f60-d8ef-d5a9863b5d39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Data Loaded...\n",
            "[INFO] Data converted to dataframe...\n"
          ]
        }
      ],
      "source": [
        "df_np = np.load(load_path, allow_pickle=True)\n",
        "\n",
        "print(\"[INFO] Data Loaded...\")\n",
        "\n",
        "df1 = pd.DataFrame(data=df_np, \\\n",
        "    columns=['document_ids', 'sentence_ids', 'sentences', 'event_type_ids', 'words', 'unique_words', 'entities', 'message_ids'])\n",
        "\n",
        "print(\"[INFO] Data converted to dataframe...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta5pRp209LMf",
        "outputId": "ed60f955-e130-49d6-a4e5-2f3099693a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10242, 8)\n"
          ]
        }
      ],
      "source": [
        "print(df1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqCn23HsGLCo",
        "outputId": "98a7c843-75c9-41b2-981a-c061cd8493c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-73c1c297-9e41-47e4-9fc5-15c69dd695c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_ids</th>\n",
              "      <th>sentence_ids</th>\n",
              "      <th>sentences</th>\n",
              "      <th>event_type_ids</th>\n",
              "      <th>words</th>\n",
              "      <th>unique_words</th>\n",
              "      <th>entities</th>\n",
              "      <th>message_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387fe1dfe55067eb29e1fd4116d37af3</td>\n",
              "      <td>14</td>\n",
              "      <td>According to author Neill Macaulay, \"he would ...</td>\n",
              "      <td>23</td>\n",
              "      <td>[accord, author, Neill, Macaulay, would, attac...</td>\n",
              "      <td>[odd, heavily, firepower, cover, orwhen, clear...</td>\n",
              "      <td>[(Neill Macaulay, PERSON)]</td>\n",
              "      <td>387fe1dfe55067eb29e1fd4116d37af3_14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>387fe1dfe55067eb29e1fd4116d37af3</td>\n",
              "      <td>10</td>\n",
              "      <td>Sandino had a tendency to greatly exaggerate n...</td>\n",
              "      <td>37</td>\n",
              "      <td>[sandino, tendency, greatly, exaggerate, numbe...</td>\n",
              "      <td>[probably, inaccurate, exaggerate, sandino, re...</td>\n",
              "      <td>[(Sandino, ORG), (60, CARDINAL)]</td>\n",
              "      <td>387fe1dfe55067eb29e1fd4116d37af3_10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>268c4763208c87ed7ebf55565c274d23</td>\n",
              "      <td>4</td>\n",
              "      <td>British forces in India were considerably stro...</td>\n",
              "      <td>42</td>\n",
              "      <td>[british, force, India, considerably, strong, ...</td>\n",
              "      <td>[strong, Cornwallis, RearAdmiral, suppoed, Wil...</td>\n",
              "      <td>[(British, NORP), (India, GPE), (French, NORP)...</td>\n",
              "      <td>268c4763208c87ed7ebf55565c274d23_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>268c4763208c87ed7ebf55565c274d23</td>\n",
              "      <td>8</td>\n",
              "      <td>British forces constructed trenches and batter...</td>\n",
              "      <td>44</td>\n",
              "      <td>[british, force, construct, trench, battery, o...</td>\n",
              "      <td>[construct, often, heavy, fire, force, british...</td>\n",
              "      <td>[(British, NORP), (the following weeks, DATE)]</td>\n",
              "      <td>268c4763208c87ed7ebf55565c274d23_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>268c4763208c87ed7ebf55565c274d23</td>\n",
              "      <td>0</td>\n",
              "      <td>\"For other sieges with this name, see Siege of...</td>\n",
              "      <td>45</td>\n",
              "      <td>[siege, name, see, Siege, Pondicherry, disambi...</td>\n",
              "      <td>[Siege, early, stage, military, French, operat...</td>\n",
              "      <td>[(Siege, FAC), (Pondicherry, GPE), (The Siege ...</td>\n",
              "      <td>268c4763208c87ed7ebf55565c274d23_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73c1c297-9e41-47e4-9fc5-15c69dd695c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73c1c297-9e41-47e4-9fc5-15c69dd695c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73c1c297-9e41-47e4-9fc5-15c69dd695c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       document_ids sentence_ids  \\\n",
              "0  387fe1dfe55067eb29e1fd4116d37af3           14   \n",
              "1  387fe1dfe55067eb29e1fd4116d37af3           10   \n",
              "2  268c4763208c87ed7ebf55565c274d23            4   \n",
              "3  268c4763208c87ed7ebf55565c274d23            8   \n",
              "4  268c4763208c87ed7ebf55565c274d23            0   \n",
              "\n",
              "                                           sentences event_type_ids  \\\n",
              "0  According to author Neill Macaulay, \"he would ...             23   \n",
              "1  Sandino had a tendency to greatly exaggerate n...             37   \n",
              "2  British forces in India were considerably stro...             42   \n",
              "3  British forces constructed trenches and batter...             44   \n",
              "4  \"For other sieges with this name, see Siege of...             45   \n",
              "\n",
              "                                               words  \\\n",
              "0  [accord, author, Neill, Macaulay, would, attac...   \n",
              "1  [sandino, tendency, greatly, exaggerate, numbe...   \n",
              "2  [british, force, India, considerably, strong, ...   \n",
              "3  [british, force, construct, trench, battery, o...   \n",
              "4  [siege, name, see, Siege, Pondicherry, disambi...   \n",
              "\n",
              "                                        unique_words  \\\n",
              "0  [odd, heavily, firepower, cover, orwhen, clear...   \n",
              "1  [probably, inaccurate, exaggerate, sandino, re...   \n",
              "2  [strong, Cornwallis, RearAdmiral, suppoed, Wil...   \n",
              "3  [construct, often, heavy, fire, force, british...   \n",
              "4  [Siege, early, stage, military, French, operat...   \n",
              "\n",
              "                                            entities  \\\n",
              "0                         [(Neill Macaulay, PERSON)]   \n",
              "1                   [(Sandino, ORG), (60, CARDINAL)]   \n",
              "2  [(British, NORP), (India, GPE), (French, NORP)...   \n",
              "3     [(British, NORP), (the following weeks, DATE)]   \n",
              "4  [(Siege, FAC), (Pondicherry, GPE), (The Siege ...   \n",
              "\n",
              "                           message_ids  \n",
              "0  387fe1dfe55067eb29e1fd4116d37af3_14  \n",
              "1  387fe1dfe55067eb29e1fd4116d37af3_10  \n",
              "2   268c4763208c87ed7ebf55565c274d23_4  \n",
              "3   268c4763208c87ed7ebf55565c274d23_8  \n",
              "4   268c4763208c87ed7ebf55565c274d23_0  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS4Ib9deG8XP"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82OGPu7e9MjS",
        "outputId": "b4de2a64-1d1d-4779-be4c-1e9c43c6e716"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "document_ids      0\n",
              "sentence_ids      0\n",
              "sentences         0\n",
              "event_type_ids    0\n",
              "words             0\n",
              "unique_words      0\n",
              "entities          0\n",
              "message_ids       0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ5KN-82IMnb",
        "outputId": "174bb5e8-639b-40e0-c131-de110f8de274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "document_ids      object\n",
              "sentence_ids      object\n",
              "sentences         object\n",
              "event_type_ids    object\n",
              "words             object\n",
              "unique_words      object\n",
              "entities          object\n",
              "message_ids       object\n",
              "dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2uENap_za5X"
      },
      "source": [
        "# Convert ids into Numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye1MgVPUxF0y"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary that maps unique string values of 'document_ids' to integers\n",
        "doc_id_map = {  doc_id:i for i, doc_id in enumerate(df1['document_ids'].unique())}\n",
        "\n",
        "# Map the 'document_ids' column to integer values\n",
        "df1['document_ids'] = df1['document_ids'].map(doc_id_map)\n",
        "\n",
        "# Convert the 'document_ids' column to integer type\n",
        "df1['document_ids'] = df1['document_ids'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZE5KPz0IOdj"
      },
      "outputs": [],
      "source": [
        "# Convert the 'sentence_ids' column to integer type\n",
        "df1['sentence_ids'] = df1['sentence_ids'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YnqRLWcwsVx"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary that maps unique string values of 'sentence_ids' to integers\n",
        "msg_id_map = {msg_id:i for i, msg_id in enumerate(df1['message_ids'].unique())}\n",
        "\n",
        "# Map the 'sentence_ids' column to integer values\n",
        "df1['message_ids'] = df1['message_ids'].map(msg_id_map)\n",
        "\n",
        "# Convert the 'sentence_ids' column to integer type\n",
        "df1['message_ids'] = df1['message_ids'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhY5NS55xtol"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to the text column\n",
        "df1['sentences'] = df1['sentences'].apply(clean_text)\n",
        "df1['sentences'] = df1['sentences'].apply(tokenize_text)\n",
        "df1['sentences'] = df1['sentences'].apply(lemmatize_tokens)\n",
        "df1['sentences'] = df1['sentences'].apply(remove_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v4CHUU5x3iw",
        "outputId": "7dd01d0f-37de-48cf-82bb-980cfe9da33d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fe8d25e7-06e7-4a39-b1ad-d68ba2d7c821\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_ids</th>\n",
              "      <th>sentence_ids</th>\n",
              "      <th>sentences</th>\n",
              "      <th>event_type_ids</th>\n",
              "      <th>words</th>\n",
              "      <th>unique_words</th>\n",
              "      <th>entities</th>\n",
              "      <th>message_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>[according, author, neill, macaulay, would, at...</td>\n",
              "      <td>23</td>\n",
              "      <td>[accord, author, Neill, Macaulay, would, attac...</td>\n",
              "      <td>[odd, heavily, firepower, cover, orwhen, clear...</td>\n",
              "      <td>[(Neill Macaulay, PERSON)]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>[sandino, tendency, greatly, exaggerate, numbe...</td>\n",
              "      <td>37</td>\n",
              "      <td>[sandino, tendency, greatly, exaggerate, numbe...</td>\n",
              "      <td>[probably, inaccurate, exaggerate, sandino, re...</td>\n",
              "      <td>[(Sandino, ORG), (60, CARDINAL)]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>[british, force, india, considerably, stronger...</td>\n",
              "      <td>42</td>\n",
              "      <td>[british, force, India, considerably, strong, ...</td>\n",
              "      <td>[strong, Cornwallis, RearAdmiral, suppoed, Wil...</td>\n",
              "      <td>[(British, NORP), (India, GPE), (French, NORP)...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>[british, force, constructed, trench, battery,...</td>\n",
              "      <td>44</td>\n",
              "      <td>[british, force, construct, trench, battery, o...</td>\n",
              "      <td>[construct, often, heavy, fire, force, british...</td>\n",
              "      <td>[(British, NORP), (the following weeks, DATE)]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[siege, name, see, siege, pondicherry, disambi...</td>\n",
              "      <td>45</td>\n",
              "      <td>[siege, name, see, Siege, Pondicherry, disambi...</td>\n",
              "      <td>[Siege, early, stage, military, French, operat...</td>\n",
              "      <td>[(Siege, FAC), (Pondicherry, GPE), (The Siege ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe8d25e7-06e7-4a39-b1ad-d68ba2d7c821')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe8d25e7-06e7-4a39-b1ad-d68ba2d7c821 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe8d25e7-06e7-4a39-b1ad-d68ba2d7c821');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   document_ids  sentence_ids  \\\n",
              "0             0            14   \n",
              "1             0            10   \n",
              "2             1             4   \n",
              "3             1             8   \n",
              "4             1             0   \n",
              "\n",
              "                                           sentences event_type_ids  \\\n",
              "0  [according, author, neill, macaulay, would, at...             23   \n",
              "1  [sandino, tendency, greatly, exaggerate, numbe...             37   \n",
              "2  [british, force, india, considerably, stronger...             42   \n",
              "3  [british, force, constructed, trench, battery,...             44   \n",
              "4  [siege, name, see, siege, pondicherry, disambi...             45   \n",
              "\n",
              "                                               words  \\\n",
              "0  [accord, author, Neill, Macaulay, would, attac...   \n",
              "1  [sandino, tendency, greatly, exaggerate, numbe...   \n",
              "2  [british, force, India, considerably, strong, ...   \n",
              "3  [british, force, construct, trench, battery, o...   \n",
              "4  [siege, name, see, Siege, Pondicherry, disambi...   \n",
              "\n",
              "                                        unique_words  \\\n",
              "0  [odd, heavily, firepower, cover, orwhen, clear...   \n",
              "1  [probably, inaccurate, exaggerate, sandino, re...   \n",
              "2  [strong, Cornwallis, RearAdmiral, suppoed, Wil...   \n",
              "3  [construct, often, heavy, fire, force, british...   \n",
              "4  [Siege, early, stage, military, French, operat...   \n",
              "\n",
              "                                            entities  message_ids  \n",
              "0                         [(Neill Macaulay, PERSON)]            0  \n",
              "1                   [(Sandino, ORG), (60, CARDINAL)]            1  \n",
              "2  [(British, NORP), (India, GPE), (French, NORP)...            2  \n",
              "3     [(British, NORP), (the following weeks, DATE)]            3  \n",
              "4  [(Siege, FAC), (Pondicherry, GPE), (The Siege ...            4  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxdJ7AlQGLCq"
      },
      "source": [
        "# FILTERING TWEETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtX1sJaSGLCq",
        "outputId": "4d55f437-97d1-42b9-9692-cd8a8f321204"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cbfa57ca-c95d-477f-8404-b0fee21cffb2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>event_id</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>user_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_loc</th>\n",
              "      <th>place_type</th>\n",
              "      <th>place_full_name</th>\n",
              "      <th>place_country_code</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_mentions</th>\n",
              "      <th>image_urls</th>\n",
              "      <th>entities</th>\n",
              "      <th>words</th>\n",
              "      <th>filtered_words</th>\n",
              "      <th>sampled_words</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68836</th>\n",
              "      <td>28486</td>\n",
              "      <td>67</td>\n",
              "      <td>265966361803640832</td>\n",
              "      <td>[“, ftofreal, state, might, legalize, marijuan...</td>\n",
              "      <td>257380081</td>\n",
              "      <td>2012-11-06 23:58:16</td>\n",
              "      <td>2 5 2</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(3, CARDINAL)]</td>\n",
              "      <td>[state, legalize, may, \", marijuana, nc, chang...</td>\n",
              "      <td>[state, legalize, may, marijuana, nc, change, ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-11-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68837</th>\n",
              "      <td>24465</td>\n",
              "      <td>52</td>\n",
              "      <td>265966512672759808</td>\n",
              "      <td>[im, watching, united, state, presidential, el...</td>\n",
              "      <td>115979133</td>\n",
              "      <td>2012-11-06 23:58:52</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[GetGlue, election2012]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(United States Presidential Election 2012, OR...</td>\n",
              "      <td>[be, United, -PRON-, other, Election, checkedi...</td>\n",
              "      <td>[be, united, other, election, checkedin, state...</td>\n",
              "      <td>[checkedin]</td>\n",
              "      <td>2012-11-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68838</th>\n",
              "      <td>24466</td>\n",
              "      <td>52</td>\n",
              "      <td>265966529496092675</td>\n",
              "      <td>[watch, election, presentation]</td>\n",
              "      <td>283768568</td>\n",
              "      <td>2012-11-06 23:58:56</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[election, watch, presentation]</td>\n",
              "      <td>[election, watch, presentation]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-11-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68839</th>\n",
              "      <td>46775</td>\n",
              "      <td>197</td>\n",
              "      <td>265966617589084160</td>\n",
              "      <td>[bombing, rock, damascus, brother, parliament,...</td>\n",
              "      <td>311802961</td>\n",
              "      <td>2012-11-06 23:59:17</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[(Damascus, GPE)]</td>\n",
              "      <td>[Anything, Damascus, rock, kill, brother, co, ...</td>\n",
              "      <td>[anything, damascus, rock, kill, brother, co, ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-11-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68840</th>\n",
              "      <td>63652</td>\n",
              "      <td>430</td>\n",
              "      <td>265966797839273984</td>\n",
              "      <td>[romney, win, idk, could, leave, country, cuz,...</td>\n",
              "      <td>432194703</td>\n",
              "      <td>2012-11-07 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[not, cuz, afford, idk, country, can, whole, w...</td>\n",
              "      <td>[not, cuz, afford, idk, country, can, whole, w...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2012-11-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbfa57ca-c95d-477f-8404-b0fee21cffb2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbfa57ca-c95d-477f-8404-b0fee21cffb2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbfa57ca-c95d-477f-8404-b0fee21cffb2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index event_id            tweet_id  \\\n",
              "68836  28486       67  265966361803640832   \n",
              "68837  24465       52  265966512672759808   \n",
              "68838  24466       52  265966529496092675   \n",
              "68839  46775      197  265966617589084160   \n",
              "68840  63652      430  265966797839273984   \n",
              "\n",
              "                                                    text    user_id  \\\n",
              "68836  [“, ftofreal, state, might, legalize, marijuan...  257380081   \n",
              "68837  [im, watching, united, state, presidential, el...  115979133   \n",
              "68838                    [watch, election, presentation]  283768568   \n",
              "68839  [bombing, rock, damascus, brother, parliament,...  311802961   \n",
              "68840  [romney, win, idk, could, leave, country, cuz,...  432194703   \n",
              "\n",
              "               created_at user_loc place_type place_full_name  \\\n",
              "68836 2012-11-06 23:58:16    2 5 2                              \n",
              "68837 2012-11-06 23:58:52                                       \n",
              "68838 2012-11-06 23:58:56                                       \n",
              "68839 2012-11-06 23:59:17                                       \n",
              "68840 2012-11-07 00:00:00                                       \n",
              "\n",
              "      place_country_code                 hashtags user_mentions image_urls  \\\n",
              "68836                                          []            []         []   \n",
              "68837                     [GetGlue, election2012]            []         []   \n",
              "68838                                          []            []         []   \n",
              "68839                                          []            []         []   \n",
              "68840                                          []            []         []   \n",
              "\n",
              "                                                entities  \\\n",
              "68836                                    [(3, CARDINAL)]   \n",
              "68837  [(United States Presidential Election 2012, OR...   \n",
              "68838                                                 []   \n",
              "68839                                  [(Damascus, GPE)]   \n",
              "68840                                                 []   \n",
              "\n",
              "                                                   words  \\\n",
              "68836  [state, legalize, may, \", marijuana, nc, chang...   \n",
              "68837  [be, United, -PRON-, other, Election, checkedi...   \n",
              "68838                    [election, watch, presentation]   \n",
              "68839  [Anything, Damascus, rock, kill, brother, co, ...   \n",
              "68840  [not, cuz, afford, idk, country, can, whole, w...   \n",
              "\n",
              "                                          filtered_words sampled_words  \\\n",
              "68836  [state, legalize, may, marijuana, nc, change, ...            []   \n",
              "68837  [be, united, other, election, checkedin, state...   [checkedin]   \n",
              "68838                    [election, watch, presentation]            []   \n",
              "68839  [anything, damascus, rock, kill, brother, co, ...            []   \n",
              "68840  [not, cuz, afford, idk, country, can, whole, w...            []   \n",
              "\n",
              "             date  \n",
              "68836  2012-11-06  \n",
              "68837  2012-11-06  \n",
              "68838  2012-11-06  \n",
              "68839  2012-11-06  \n",
              "68840  2012-11-07  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frqgf4W4Nz2g",
        "outputId": "d6216087-70ae-467a-c6ca-409b1109fb08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjinSrZkGLCq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
        "\n",
        "# Check if a GPU is available and use it\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained sentiment analysis model and tokenizer\n",
        "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
        "\n",
        "# Create the sentiment analysis pipeline\n",
        "sentiment_analyzer = TextClassificationPipeline(model=model, tokenizer=tokenizer, task='sentiment-analysis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiDpGUw8GLCr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK0W3A7gGLCr",
        "outputId": "d2426e80-287b-4ff9-8151-0c327bb6fbe1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9992014765739441"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analyzer(df.text[68839])[0]['score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLWAvpjoGLCr"
      },
      "outputs": [],
      "source": [
        "messages =  df.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwFMJpMQGLCr",
        "outputId": "8b7fb5ca-53f9-49e8-d8ef-512d45f7ce50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 425/1076 [59:59<1:31:55,  8.47s/it]"
          ]
        }
      ],
      "source": [
        "# Compute the sentiment scores for each message\n",
        "batch_size = 64\n",
        "sentiment_scores = []\n",
        "for i in tqdm.tqdm(range(0, len(messages), batch_size)):\n",
        "    batch = messages[i:i + batch_size].apply(str).tolist()\n",
        "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "    for probability in probabilities:\n",
        "        sentiment_scores.append(probability[1])  # Get the score for the positive sentiment class\n",
        "\n",
        "\n",
        "# Add sentiment scores to the DataFrame\n",
        "df['sentiment_scores'] = sentiment_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk-OKxXVGLCr"
      },
      "outputs": [],
      "source": [
        "# df.to_csv(\"processed_tweets_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILylOw4hGLCr"
      },
      "outputs": [],
      "source": [
        "new_DF = pd.read_csv(\"processed_tweets_data.csv\")\n",
        "new_DF['sentiment_scores'].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE-elhFQGLCs"
      },
      "outputs": [],
      "source": [
        "threshold = 0.5\n",
        "\n",
        "filtered_df = new_DF[new_DF['sentiment_scores'] >= threshold]\n",
        "filtered_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XGSQNSvGLCs"
      },
      "outputs": [],
      "source": [
        "print(\"TOTAL MESSAGES: \", len(new_DF))\n",
        "print(\"FILTERED MESSAGES:\", len(filtered_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTS3r37RGLCs"
      },
      "outputs": [],
      "source": [
        "# # Set batch size and preallocate list for sentiment scores\n",
        "# batch_size = 256\n",
        "# sentiment_labels = []\n",
        "\n",
        "# # Process messages in batches\n",
        "# for i in tqdm.tqdm(range(0, len(messages), batch_size)):\n",
        "#     batch = messages[i:i + batch_size].apply(str).tolist()\n",
        "#     results = sentiment_analyzer(batch)\n",
        "#     for result in results:\n",
        "#         sentiment_labels.append(result['label'])\n",
        "\n",
        "# # Add sentiment scores to the DataFrame\n",
        "# df['sentiment_labels'] = sentiment_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMHr7VPPGLCs"
      },
      "outputs": [],
      "source": [
        "filtered_df.drop(['sentiment_scores'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi3adCY2GLCs"
      },
      "source": [
        "# Generating the initial message features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPJBETxDGLCs"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywkwk2JHGLCt"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "This function encodes a timestamp string in the format '2012-10-11 07:19:34' into a list of two time features.\n",
        "'''\n",
        "\n",
        "def extract_time_features(timestamp_str):\n",
        "    # Convert the timestamp string to a datetime object\n",
        "    timestamp = datetime.fromisoformat(str(timestamp_str))\n",
        "    # Define a datetime object to represent the zero time for OLE time\n",
        "    OLE_TIME_ZERO = datetime(1899, 12, 30)\n",
        "    # Calculate the time difference between the timestamp and the OLE time zero\n",
        "    delta = timestamp - OLE_TIME_ZERO\n",
        "    # Calculate the time features by normalizing the time difference into fractions of a day\n",
        "    time_features = [(float(delta.days) / 100000.), (float(delta.seconds) / 86400)] # 86,400 seconds in a day\n",
        "    # Return the time features as a list\n",
        "    return time_features\n",
        "\n",
        "'''\n",
        "This function encodes the timestamps of all the messages in the dataframe into a numpy array of time features.\n",
        "'''\n",
        "def get_time_features(df):\n",
        "    # Apply the extract_time_features function on each timestamp string in the dataframe\n",
        "    time_features = np.asarray([extract_time_features(timestamp_str) for timestamp_str in df['created_at']])\n",
        "    # Return the time features as a numpy array\n",
        "    return time_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSAwXvSKGLCt"
      },
      "outputs": [],
      "source": [
        "filtered_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e1yjRYPGLCt"
      },
      "outputs": [],
      "source": [
        "df['filtered_words'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn8kVo9XGLCt"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "# Load the pre-trained BERT model\n",
        "def load_bert_model():\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    return model, tokenizer\n",
        "\n",
        "# Generate embeddings using the BERT model for a batch of data\n",
        "def get_bert_embeddings_batch(batch, model, tokenizer):\n",
        "    # Tokenize the input text and convert it to tensors\n",
        "    input_data = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
        "    \n",
        "    # Obtain the hidden states from the BERT model\n",
        "    with torch.no_grad():\n",
        "        output = model(**input_data)\n",
        "    \n",
        "    # Use the mean of the last hidden states as the embedding\n",
        "    embeddings = output.last_hidden_state.mean(dim=1).numpy()\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "# Process the data in smaller batches\n",
        "def get_bert_embeddings(df, model, tokenizer, batch_size=32):\n",
        "    embeddings = []\n",
        "    for i in tqdm.tqdm(range(0, len(df), batch_size)):\n",
        "        batch = df['filtered_words'][i:i+batch_size].apply(lambda x: ' '.join(x)).tolist()\n",
        "        batch_embeddings = get_bert_embeddings_batch(batch, model, tokenizer)\n",
        "        embeddings.append(batch_embeddings)\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Example usage\n",
        "bert_model, bert_tokenizer = load_bert_model()\n",
        "document_embeddings = get_bert_embeddings(df, bert_model, bert_tokenizer)\n",
        "document_embeddings[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FsuKKF2GLCt"
      },
      "outputs": [],
      "source": [
        "document_embeddings[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynYxLIu6GLCt"
      },
      "outputs": [],
      "source": [
        "document_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Qt3o7g4GLCu"
      },
      "outputs": [],
      "source": [
        "time_features = get_time_features(df)\n",
        "\n",
        "print(\"Time features generated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMAwJsHgGLCu"
      },
      "outputs": [],
      "source": [
        "time_features[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHmfUHpHGLCu"
      },
      "outputs": [],
      "source": [
        "time_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMEmIrE7GLCu"
      },
      "outputs": [],
      "source": [
        "# Concatenate the document features and time features into a single numpy array\n",
        "combined_features = np.concatenate((document_embeddings, time_features), axis=1)\n",
        "print(\"Concatenated document features and time features.\")\n",
        "combined_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf01z4BQGLCu"
      },
      "outputs": [],
      "source": [
        "# Save the concatenated features as a numpy array file\n",
        "save_file_path =  'BERT_Full_features_69612_0709_spacy_lg_zero_multiclasses_filtered.npy'\n",
        "np.save(save_file_path, combined_features)\n",
        "print(\"Initial features saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyVHLtOwGLCu"
      },
      "outputs": [],
      "source": [
        "# Load the concatenated features from the saved numpy array file\n",
        "loaded_features = np.load(save_file_path)\n",
        "print(\"Initial features loaded.\")\n",
        "print(loaded_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvD-HNSMGLCv"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clTmFqSoGLCv"
      },
      "source": [
        "# CONSTRUCTING GRAPHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT_kUu0CGLCv"
      },
      "outputs": [],
      "source": [
        "def construct_graph_from_df(df, G=None):\n",
        "    if G is None:\n",
        "        G = nx.Graph()\n",
        "    for _, row in df.iterrows():\n",
        "        tid = 't_' + str(row['tweet_id'])\n",
        "        G.add_node(tid)\n",
        "        G.nodes[tid]['tweet_id'] = True  # right-hand side value is irrelevant for the lookup\n",
        "\n",
        "        user_ids = row['user_mentions']\n",
        "        user_ids  = list(user_ids)\n",
        "        user_ids.append(row['user_id'])\n",
        "        user_ids = ['u_' + str(each) for each in user_ids]\n",
        "        # print(user_ids)\n",
        "        G.add_nodes_from(user_ids)\n",
        "        for each in user_ids:\n",
        "            G._node[each]['user_id'] = True\n",
        "\n",
        "        entities = row['entities']\n",
        "        # entities = ['e_' + each for each in entities]\n",
        "        # print(entities)\n",
        "        G.add_nodes_from(entities)\n",
        "        for each in entities:\n",
        "            G._node[each]['entity'] = True\n",
        "\n",
        "        words = row['sampled_words']\n",
        "        words = ['w_' + each for each in words]\n",
        "        # print(words)\n",
        "        G.add_nodes_from(words)\n",
        "        for each in words:\n",
        "            G._node[each]['word'] = True\n",
        "\n",
        "        edges = []\n",
        "        edges += [(tid, each) for each in user_ids]\n",
        "        edges += [(tid, each) for each in entities]\n",
        "        edges += [(tid, each) for each in words]\n",
        "        G.add_edges_from(edges)\n",
        "\n",
        "    return G\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95oguRS0GLCv"
      },
      "outputs": [],
      "source": [
        "# convert a heterogeneous social graph G to a homogeneous message graph following eq. 1 of the paper,\n",
        "# and store the sparse binary adjacency matrix of the homogeneous message graph.\n",
        "\n",
        "\n",
        "def to_dgl_graph_v3(G, save_path=None):\n",
        "    message = ''\n",
        "    print('Start converting heterogeneous networkx graph to homogeneous dgl graph.')\n",
        "    message += 'Start converting heterogeneous networkx graph to homogeneous dgl graph.\\n'\n",
        "    all_start = time()\n",
        "\n",
        "    print('\\tGetting a list of all nodes ...')\n",
        "    message += '\\tGetting a list of all nodes ...\\n'\n",
        "    start = time()\n",
        "    all_nodes = list(G.nodes)\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # print('All nodes: ', all_nodes)\n",
        "    # print('Total number of nodes: ', len(all_nodes))\n",
        "\n",
        "    print('\\tGetting adjacency matrix ...')\n",
        "    message += '\\tGetting adjacency matrix ...\\n'\n",
        "    start = time()\n",
        "    A = nx.to_numpy_matrix(G)  # Returns the graph adjacency matrix as a NumPy matrix.\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # compute commuting matrices\n",
        "    print('\\tGetting lists of nodes of various types ...')\n",
        "    message += '\\tGetting lists of nodes of various types ...\\n'\n",
        "    start = time()\n",
        "    tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys())\n",
        "    userid_nodes = list(nx.get_node_attributes(G, 'user_id').keys())\n",
        "    word_nodes = list(nx.get_node_attributes(G, 'word').keys())\n",
        "    entity_nodes = list(nx.get_node_attributes(G, 'entity').keys())\n",
        "    del G\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\tConverting node lists to index lists ...')\n",
        "    message += '\\tConverting node lists to index lists ...\\n'\n",
        "    start = time()\n",
        "    #  find the index of target nodes in the list of all_nodes\n",
        "    indices_tid = [all_nodes.index(x) for x in tid_nodes]\n",
        "    indices_userid = [all_nodes.index(x) for x in userid_nodes]\n",
        "    indices_word = [all_nodes.index(x) for x in word_nodes]\n",
        "    indices_entity = [all_nodes.index(x) for x in entity_nodes]\n",
        "    del tid_nodes\n",
        "    del userid_nodes\n",
        "    del word_nodes\n",
        "    del entity_nodes\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # ----------------------tweet-user-tweet----------------------\n",
        "    print('\\tStart constructing tweet-user-tweet commuting matrix ...')\n",
        "    print('\\t\\t\\tStart constructing tweet-user matrix ...')\n",
        "    message += '\\tStart constructing tweet-user-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-user ' \\\n",
        "               'matrix ...\\n '\n",
        "    start = time()\n",
        "    w_tid_userid = A[np.ix_(indices_tid, indices_userid)]\n",
        "    #  return a N(indices_tid)*N(indices_userid) matrix, representing the weight of edges between tid and userid\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # convert to scipy sparse matrix\n",
        "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
        "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
        "    start = time()\n",
        "    s_w_tid_userid = sparse.csr_matrix(w_tid_userid)  # matrix compression\n",
        "    del w_tid_userid\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tTransposing ...')\n",
        "    message += '\\t\\t\\tTransposing ...\\n'\n",
        "    start = time()\n",
        "    s_w_userid_tid = s_w_tid_userid.transpose()\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tCalculating tweet-user * user-tweet ...')\n",
        "    message += '\\t\\t\\tCalculating tweet-user * user-tweet ...\\n'\n",
        "    start = time()\n",
        "    s_m_tid_userid_tid = s_w_tid_userid * s_w_userid_tid  # homogeneous message graph\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tSaving ...')\n",
        "    message += '\\t\\t\\tSaving ...\\n'\n",
        "    start = time()\n",
        "    if save_path is not None:\n",
        "        sparse.save_npz(save_path + \"s_m_tid_userid_tid.npz\", s_m_tid_userid_tid)\n",
        "        print(\"Sparse binary userid commuting matrix saved.\")\n",
        "        del s_m_tid_userid_tid\n",
        "    del s_w_tid_userid\n",
        "    del s_w_userid_tid\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # ----------------------tweet-ent-tweet------------------------\n",
        "    print('\\tStart constructing tweet-ent-tweet commuting matrix ...')\n",
        "    print('\\t\\t\\tStart constructing tweet-ent matrix ...')\n",
        "    message += '\\tStart constructing tweet-ent-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-ent matrix ' \\\n",
        "               '...\\n '\n",
        "    start = time()\n",
        "    w_tid_entity = A[np.ix_(indices_tid, indices_entity)]\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # convert to scipy sparse matrix\n",
        "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
        "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
        "    start = time()\n",
        "    s_w_tid_entity = sparse.csr_matrix(w_tid_entity)\n",
        "    del w_tid_entity\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tTransposing ...')\n",
        "    message += '\\t\\t\\tTransposing ...\\n'\n",
        "    start = time()\n",
        "    s_w_entity_tid = s_w_tid_entity.transpose()\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tCalculating tweet-ent * ent-tweet ...')\n",
        "    message += '\\t\\t\\tCalculating tweet-ent * ent-tweet ...\\n'\n",
        "    start = time()\n",
        "    s_m_tid_entity_tid = s_w_tid_entity * s_w_entity_tid\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tSaving ...')\n",
        "    message += '\\t\\t\\tSaving ...\\n'\n",
        "    start = time()\n",
        "    if save_path is not None:\n",
        "        sparse.save_npz(save_path + \"s_m_tid_entity_tid.npz\", s_m_tid_entity_tid)\n",
        "        print(\"Sparse binary entity commuting matrix saved.\")\n",
        "        del s_m_tid_entity_tid\n",
        "    del s_w_tid_entity\n",
        "    del s_w_entity_tid\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # ----------------------tweet-word-tweet----------------------\n",
        "    print('\\tStart constructing tweet-word-tweet commuting matrix ...')\n",
        "    print('\\t\\t\\tStart constructing tweet-word matrix ...')\n",
        "    message += '\\tStart constructing tweet-word-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-word ' \\\n",
        "               'matrix ...\\n '\n",
        "    start = time()\n",
        "    w_tid_word = A[np.ix_(indices_tid, indices_word)]\n",
        "    del A\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # convert to scipy sparse matrix\n",
        "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
        "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
        "    start = time()\n",
        "    s_w_tid_word = sparse.csr_matrix(w_tid_word)\n",
        "    del w_tid_word\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tTransposing ...')\n",
        "    message += '\\t\\t\\tTransposing ...\\n'\n",
        "    start = time()\n",
        "    s_w_word_tid = s_w_tid_word.transpose()\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tCalculating tweet-word * word-tweet ...')\n",
        "    message += '\\t\\t\\tCalculating tweet-word * word-tweet ...\\n'\n",
        "    start = time()\n",
        "    s_m_tid_word_tid = s_w_tid_word * s_w_word_tid\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    print('\\t\\t\\tSaving ...')\n",
        "    message += '\\t\\t\\tSaving ...\\n'\n",
        "    start = time()\n",
        "    if save_path is not None:\n",
        "        sparse.save_npz(save_path + \"s_m_tid_word_tid.npz\", s_m_tid_word_tid)\n",
        "        print(\"Sparse binary word commuting matrix saved.\")\n",
        "        del s_m_tid_word_tid\n",
        "    del s_w_tid_word\n",
        "    del s_w_word_tid\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    # ----------------------compute tweet-tweet adjacency matrix----------------------\n",
        "    print('\\tComputing tweet-tweet adjacency matrix ...')\n",
        "    message += '\\tComputing tweet-tweet adjacency matrix ...\\n'\n",
        "    start = time()\n",
        "    if save_path is not None:\n",
        "        s_m_tid_userid_tid = sparse.load_npz(save_path + \"s_m_tid_userid_tid.npz\")\n",
        "        print(\"Sparse binary userid commuting matrix loaded.\")\n",
        "        s_m_tid_entity_tid = sparse.load_npz(save_path + \"s_m_tid_entity_tid.npz\")\n",
        "        print(\"Sparse binary entity commuting matrix loaded.\")\n",
        "        s_m_tid_word_tid = sparse.load_npz(save_path + \"s_m_tid_word_tid.npz\")\n",
        "        print(\"Sparse binary word commuting matrix loaded.\")\n",
        "\n",
        "    s_A_tid_tid = s_m_tid_userid_tid + s_m_tid_entity_tid\n",
        "    del s_m_tid_userid_tid\n",
        "    del s_m_tid_entity_tid\n",
        "    s_bool_A_tid_tid = (s_A_tid_tid + s_m_tid_word_tid).astype('bool')  # confirm the connect between tweets\n",
        "    del s_m_tid_word_tid\n",
        "    del s_A_tid_tid\n",
        "    mins = (time() - start) / 60\n",
        "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
        "    message += '\\t\\t\\tDone. Time elapsed: '\n",
        "    message += str(mins)\n",
        "    message += ' mins\\n'\n",
        "    all_mins = (time() - all_start) / 60\n",
        "    print('\\tOver all time elapsed: ', all_mins, ' mins\\n')\n",
        "    message += '\\tOver all time elapsed: '\n",
        "    message += str(all_mins)\n",
        "    message += ' mins\\n'\n",
        "\n",
        "    if save_path is not None:\n",
        "        sparse.save_npz(save_path + \"s_bool_A_tid_tid.npz\", s_bool_A_tid_tid)\n",
        "        print(\"Sparse binary adjacency matrix saved.\")\n",
        "        s_bool_A_tid_tid = sparse.load_npz(save_path + \"s_bool_A_tid_tid.npz\")\n",
        "        print(\"Sparse binary adjacency matrix loaded.\")\n",
        "\n",
        "    # create corresponding dgl graph\n",
        "    G = dgl.DGLGraph(s_bool_A_tid_tid)\n",
        "    print('We have %d nodes.' % G.number_of_nodes())\n",
        "    print('We have %d edges.' % G.number_of_edges())\n",
        "    print()\n",
        "    message += 'We have '\n",
        "    message += str(G.number_of_nodes())\n",
        "    message += ' nodes.'\n",
        "    message += 'We have '\n",
        "    message += str(G.number_of_edges())\n",
        "    message += ' edges.\\n'\n",
        "\n",
        "    return all_mins, message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmuFsfi_GLCw"
      },
      "outputs": [],
      "source": [
        "def construct_incremental_dataset_0922(df, save_path, features, test=True):\n",
        "    # If test equals true, construct the initial graph using test_ini_size tweets\n",
        "    # and increment the graph by test_incr_size tweets each day\n",
        "    test_ini_size = 500\n",
        "    test_incr_size = 100\n",
        "\n",
        "    # save data splits for training/validate/test mask generation\n",
        "    data_split = []\n",
        "    # save time spent for the heterogeneous -> homogeneous conversion of each graph\n",
        "    all_graph_mins = []\n",
        "    message = \"\"\n",
        "    # extract distinct dates\n",
        "    distinct_dates = df.date.unique()  # 2012-11-07\n",
        "    # print(\"Distinct dates: \", distinct_dates)\n",
        "    print(\"Number of distinct dates: \", len(distinct_dates))\n",
        "    print()\n",
        "    message += \"Number of distinct dates: \"\n",
        "    message += str(len(distinct_dates))\n",
        "    message += \"\\n\"\n",
        "\n",
        "    # split data by dates and construct graphs\n",
        "    # first week -> initial graph (20254 tweets)\n",
        "    print(\"Start constructing initial graph ...\")\n",
        "    message += \"\\nStart constructing initial graph ...\\n\"\n",
        "    ini_df = df.loc[df['date'].isin(distinct_dates[:7])]  # find top 7 dates\n",
        "    if test:\n",
        "        ini_df = ini_df[:test_ini_size]  # top test_ini_size dates\n",
        "    G = construct_graph_from_df(ini_df)\n",
        "    path = save_path + '0/'\n",
        "    os.mkdir(path)\n",
        "    grap_mins, graph_message = to_dgl_graph_v3(G, save_path=path)\n",
        "    message += graph_message\n",
        "    print(\"Initial graph saved\")\n",
        "    message += \"Initial graph saved\\n\"\n",
        "    # record the total number of tweets\n",
        "    data_split.append(ini_df.shape[0])\n",
        "    # record the time spent for graph conversion\n",
        "    all_graph_mins.append(grap_mins)\n",
        "    # extract and save the labels of corresponding tweets\n",
        "    y = ini_df['event_id'].values\n",
        "    y = [int(each) for each in y]\n",
        "    np.save(path + 'labels.npy', np.asarray(y))\n",
        "    print(\"Labels saved.\")\n",
        "    message += \"Labels saved.\\n\"\n",
        "    # extract and save the features of corresponding tweets\n",
        "    indices = ini_df['index'].values.astype(np.int8).tolist()\n",
        "    x = features[indices, :]\n",
        "    np.save(path + 'features.npy', x)\n",
        "    print(\"Features saved.\")\n",
        "    message += \"Features saved.\\n\\n\"\n",
        "\n",
        "    # subsequent days -> insert tweets day by day (skip the last day because it only contains one tweet)\n",
        "    for i in range(7, len(distinct_dates) - 1):\n",
        "        print(\"Start constructing graph \", str(i - 6), \" ...\")\n",
        "        message += \"\\nStart constructing graph \"\n",
        "        message += str(i - 6)\n",
        "        message += \" ...\\n\"\n",
        "        incr_df = df.loc[df['date'] == distinct_dates[i]]\n",
        "        if test:\n",
        "            incr_df = incr_df[:test_incr_size]\n",
        "\n",
        "        # All/Relevant Message Strategy: keeping all the messages when constructing the graphs\n",
        "        # (for the Relevant Message Strategy, the unrelated messages will be removed from the graph later on).\n",
        "        # G = construct_graph_from_df(incr_df, G)\n",
        "\n",
        "        # Latest Message Strategy: construct graph using only the data of the day\n",
        "        G = construct_graph_from_df(incr_df)\n",
        "\n",
        "        path = save_path + str(i - 6) + '/'\n",
        "        os.mkdir(path)\n",
        "        grap_mins, graph_message = to_dgl_graph_v3(G, save_path=path)\n",
        "        message += graph_message\n",
        "        print(\"Graph \", str(i - 6), \" saved\")\n",
        "        message += \"Graph \"\n",
        "        message += str(i - 6)\n",
        "        message += \" saved\\n\"\n",
        "        # record the total number of tweets\n",
        "        data_split.append(incr_df.shape[0])\n",
        "        # record the time spent for graph conversion\n",
        "        all_graph_mins.append(grap_mins)\n",
        "        # extract and save the labels of corresponding tweets\n",
        "        # y = np.concatenate([y, incr_df['event_id'].values], axis = 0)\n",
        "        y = [int(each) for each in incr_df['event_id'].values]\n",
        "        np.save(path + 'labels.npy', y)\n",
        "        print(\"Labels saved.\")\n",
        "        message += \"Labels saved.\\n\"\n",
        "        # extract and save the features of corresponding tweets\n",
        "        indices = incr_df['index'].values.astype(np.int8).tolist()\n",
        "        x = features[indices, :]\n",
        "        # x = np.concatenate([x, x_incr], axis = 0)\n",
        "        np.save(path + 'features.npy', x)\n",
        "        print(\"Features saved.\")\n",
        "        message += \"Features saved.\\n\"\n",
        "\n",
        "    return message, data_split, all_graph_mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWRE-3dXGLCw"
      },
      "outputs": [],
      "source": [
        "len(loaded_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN7R-TbWGLCw"
      },
      "outputs": [],
      "source": [
        "# load features\n",
        "# the dimension of feature is 300 in this dataset\n",
        "\n",
        "# loaded_features = np.load('features_69612_0709_spacy_lg_zero_multiclasses_filtered.npy')\n",
        "save_path = 'data_bert/'\n",
        "\n",
        "# generate test graphs, features, and labels\n",
        "message, data_split, all_graph_mins = construct_incremental_dataset_0922(df, save_path, loaded_features, True)\n",
        "with open(\"bert_full_node_edge_statistics.txt\", \"w\") as text_file:\n",
        "    text_file.write(message)\n",
        "\n",
        "np.save('bert_full_data_split.npy', np.asarray(data_split))\n",
        "print(\"Data split: \", data_split)\n",
        "np.save('bert_full_all_graph_mins.npy', np.asarray(all_graph_mins))\n",
        "print(\"Time sepnt on heterogeneous -> homogeneous graph conversions: \", all_graph_mins)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjTIo3GJGLCx"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aECAr2tBGLCx"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juCX_OA0GLCx"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}